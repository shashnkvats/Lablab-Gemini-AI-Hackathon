{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxpQ6cf1645V"
      },
      "outputs": [],
      "source": [
        "!pip install trulens-eval==0.19.1 llama-index==0.9.19 chromadb streamlit_javascript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8--3F5c46_al",
        "outputId": "bfd93db3-fb5b-401f-fb7c-6d4314610b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pydantic==2.5.2\n",
            "pydantic_core==2.14.5\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQBomyqHETyR",
        "outputId": "74d6dea3-0dff-4bf5-f9d8-fa3652f478cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trulens-eval==0.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep trulens-eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HnPpPrpEaWz",
        "outputId": "c2c36f42-d92b-4672-fbb7-faa882a40124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama-index==0.9.19\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8PFmlyWD-jo",
        "outputId": "6d914f70-8537-48f7-e0ec-b830997e5e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n",
            "Starting dashboard ...\n",
            "npx: installed 22 in 4.238s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://legal-points-look.loca.lt\n",
            "\n",
            "  Submit this IP Address: 34.74.141.85\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from trulens_eval import Tru\n",
        "tru = Tru()\n",
        "tru.run_dashboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3u_DqHD7D_IP"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
        "from llama_index.embeddings import OpenAIEmbedding\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.vector_stores import QdrantVectorStore\n",
        "from llama_index import StorageContext\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBDcbXFPFk3i",
        "outputId": "a22bf207-e282-4c62-96e9-ae67a0785cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import json\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "project_id = userdata.get('PROJECT_ID')\n",
        "!gcloud config set project {project_id}\n",
        "# !gcloud auth application-default login\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QayFirYlE0kE"
      },
      "outputs": [],
      "source": [
        "# Create a local Qdrant vector store\n",
        "import chromadb\n",
        "from llama_index.vector_stores import ChromaVectorStore\n",
        "\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "# chroma_collection = chroma_client.create_collection(\"chroma_store\")\n",
        "vector_store = ChromaVectorStore(\n",
        "    chroma_collection=\"chroma_store\",\n",
        ")\n",
        "\n",
        "\n",
        "# Using the embedding model to Gemini\n",
        "embed_model = OpenAIEmbedding(\n",
        "    model_name=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=OpenAI(api_key=OPENAI_API_KEY), embed_model=embed_model\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, service_context=service_context\n",
        ")\n",
        "\n",
        "index.storage_context.persist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(chroma_collection.get())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0mPoCFWMw-E",
        "outputId": "f33cc68f-536d-41ce-ce7c-416317b643bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r storage.zip /content/storage/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E6NxJqbw9l7",
        "outputId": "bc0de4a6-218a-411d-f00d-8c77c6be3fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/storage/ (stored 0%)\n",
            "  adding: content/storage/default__vector_store.json (deflated 60%)\n",
            "  adding: content/storage/index_store.json (deflated 49%)\n",
            "  adding: content/storage/graph_store.json (stored 0%)\n",
            "  adding: content/storage/docstore.json (deflated 70%)\n",
            "  adding: content/storage/image__vector_store.json (deflated 19%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class InsaProfile(BaseModel):\n",
        "    \"\"\"Data model for a InsaProfile.\"\"\"\n",
        "    handle: str\n",
        "    name: str\n",
        "    email: str\n",
        "    bio: str\n",
        "    profile_image_url: str"
      ],
      "metadata": {
        "id": "SQpjk4w6BGmi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTLhFPwqJpjw",
        "outputId": "fb0e7906-361c-4bcb-8b4d-ffdf712a8fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "handle='sincerelyjules' name='JULIE SARINÌƒANA' email='jen@jenniferpowell.com' bio='california girl dreaming big. âœ¿ \\nfounder of @colordept\\nagent: jen@jenniferpowell.com\\nshop my line at TjMaxx, Marshallâ€™s + Homegoods' profile_image_url=''\n",
            "<class '__main__.InsaProfile'>\n"
          ]
        }
      ],
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir='/content/storage')\n",
        "index = load_index_from_storage(storage_context, service_context = service_context)\n",
        "\n",
        "query_engine = index.as_query_engine(output_cls=InsaProfile, response_mode=\"compact\")\n",
        "response = query_engine.query(\"give me all index details\")\n",
        "# print(f\"Response: {response}\")\n",
        "print(response.response)\n",
        "print(type(response.response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bw020udCKTKl"
      },
      "outputs": [],
      "source": [
        "#RAG using lamaindex and evaluate using trulens\n",
        "\n",
        "from trulens_eval import Feedback\n",
        "from trulens_eval.feedback.provider import OpenAI\n",
        "# from trulens_eval.feedback.provider import Huggingface\n",
        "\n",
        "\n",
        "# Initialize provider class\n",
        "provider = OpenAI()\n",
        "# hugs_provider = Huggingface()\n",
        "\n",
        "# LLM-based feedback functions\n",
        "f_controversiality = Feedback(\n",
        "    provider.controversiality_with_cot_reasons,\n",
        "    name=\"Controversiality\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "f_criminality = Feedback(\n",
        "    provider.criminality_with_cot_reasons,\n",
        "    name=\"Criminality\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "f_insensitivity = Feedback(\n",
        "    provider.insensitivity_with_cot_reasons,\n",
        "    name=\"Insensitivity\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "f_maliciousness = Feedback(\n",
        "    provider.maliciousness_with_cot_reasons,\n",
        "    name=\"Maliciousness\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "# Moderation feedback functions\n",
        "f_hate = Feedback(\n",
        "    provider.moderation_hate,\n",
        "    name=\"Hate\",\n",
        "    higher_is_better=False\n",
        "    ).on_output()\n",
        "\n",
        "f_hatethreatening = Feedback(\n",
        "    provider.moderation_hatethreatening,\n",
        "    name=\"Hate/Threatening\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "f_violent = Feedback(\n",
        "    provider.moderation_violence,\n",
        "    name=\"Violent\",\n",
        "    higher_is_better=False\n",
        "    ).on_output()\n",
        "\n",
        "f_violentgraphic = Feedback(\n",
        "    provider.moderation_violencegraphic,\n",
        "    name=\"Violent/Graphic\",\n",
        "    higher_is_better=False,\n",
        "    ).on_output()\n",
        "\n",
        "f_selfharm = Feedback(\n",
        "    provider.moderation_selfharm,\n",
        "    name=\"Self Harm\",\n",
        "    higher_is_better=False\n",
        "    ).on_output()\n",
        "\n",
        "harmless_feedbacks = [\n",
        "    f_controversiality,\n",
        "    f_criminality,\n",
        "    f_insensitivity,\n",
        "    f_maliciousness,\n",
        "    f_hate,\n",
        "    f_hatethreatening,\n",
        "    f_violent,\n",
        "    f_violentgraphic,\n",
        "    f_selfharm,\n",
        "    ]\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=1,\n",
        ")\n",
        "\n",
        "from trulens_eval import TruLlama\n",
        "\n",
        "tru_query_engine_recorder = TruLlama(\n",
        "        query_engine,\n",
        "        app_id='Multi-index query harmless feedback',\n",
        "        feedbacks=harmless_feedbacks\n",
        "    )\n",
        "with tru_query_engine_recorder as recording:\n",
        "    response = query_engine.query(\"What did the author do growing up?\")\n",
        "\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}